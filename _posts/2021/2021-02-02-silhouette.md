---
title: "使用轮廓系数吧"
image: posts/20210201/workflow.png.webp
categories:
  - 数据分析
tags:
  - 聚类
---

**轮廓系数** (使用[轮廓图]) 显示簇内样本与最近簇内样本之间的平均距离。 






对于给定的数据，接近 1 的轮廓系数表示数据样本靠近簇中心。轮廓系数接近 0 的样本位于两个簇之间的边界上。总体而言，可以通过数据样本的平均轮廓系数来评估聚类的质量。但是在这里，我们对各个轮廓及其在轮廓图中的可视化更加感兴趣。

## 小实验
仍然使用 *iris* 数据集, 我们将会计算每个数据点的轮廓系数. 

![](/assets/images/posts/20210202/workflow.png.webp)

在[k均值]中设置聚类数量为 3, 然后用[轮廓图]显示. 好的簇的数据的轮廓系数大, 不过这里我们做点不一样的, 我们特意选择那些轮廓系数小的点, 看看他们有什么特点?

我们可以发现, 他们都位于两个簇的交界, 从[散点图]可以很清楚的看到看出来

![](/assets/images/posts/20210202/scatterplot.png.webp)

> 在这个工作流中, 我们还使用了[着色]小部件, 这是为了让[散点图]和[轮廓图]对应的颜色一致.

[<i class="fas fa-cloud-download-alt"></i>下载本工作流](/assets/workflows/2021/simple-silhouette.ows)

## 进一步分析

让我们再做些更有意思的事情。我们将在 *iris* 的类别属性上计算轮廓系数（此处不进行聚类，仅使用数据集中的原始类值）。我们的假设是：具有低轮廓值的数据也将被某些学习算法(比如[随机森林])误分类,。

我们将在[测试与评分]中使用10次折叠交叉验证，将评估结果发送到[混淆矩阵]，然后选择分类错误的数据。接下来，我们在[维恩图]中探索低轮廓系数值的数据。两种技术之间的交集比例很高。

![](/assets/images/posts/20210202/intersection.png.webp)

[轮廓图]是另一种出色的可视化方法，可以帮助你进行数据分析或理解某些机器学习概念。

[<i class="fas fa-cloud-download-alt"></i>下载本工作流](/assets/workflows/2021/adv-silhouette.ows)


{% include _links.md %}